---
title: "p8105_hw3_kk3154"
author: "Kristen King"
date: "10/20/2021"
output: github_document
---

```{r, message = FALSE}
library(tidyverse)
library(viridis)

knitr::opts_chunk$set(
  fid.width = 6, 
  fig.asp = 0.6,
  out.width = "90%")

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis")


scale_color_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1 - Exploring Instacart Data

Loading data from p8105.datasets:

```{r, message = FALSE}
library(p8105.datasets)
data("instacart")
```

**1.1** Describe the dataset, including size and structure of the data, key variables, and giving illustrative examples of observations.

```{r}
insta_df = instacart
```

The Instacart dataset contains `r ncol(insta_df)` variables of data on `r nrow(insta_df)` products ordered in the instacart app. Each row is one product from each order, and some identifying variables include order ID, customer ID, day/time of order, and time since last order. Key variables for potential analysis include product, aisle, and department IDs and names. For example, observation #9 in the dataset indicates customer number `r insta_df[9, "user_id"]` ordered `r insta_df[9, "product_name"]` from the `r insta_df[9, "aisle"]` aisle in the `r insta_df[9, "department"]` department as part of their order number `r insta_df[9, "order_id"]` at time `r insta_df[9, "order_hour_of_day"]`:00 on the `r insta_df[9, "order_dow"]`th day of the week.


**1.2** How many aisles are there, and which aisles are the most items ordered from?

```{r}
aisle_count = 
  insta_df %>% 
  mutate(aisle = factor(aisle)) %>% 
  group_by(aisle) %>% 
  summarize(n_items = n()) %>% 
  arrange(desc(n_items)) 

aisle_count %>%  
  head() %>% 
  knitr::kable()
```

There are `r nrow(aisle_count)` aisles in this dataset, and the `r pull(head(aisle_count), aisle)` aisles have the most items ordered from them.


**1.3** Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r}
insta_df %>% 
  mutate(aisle = factor(aisle)) %>% 
  group_by(aisle) %>% 
  summarize(n_items = n()) %>% 
  filter(n_items > 10000) %>% 
  mutate(
    aisle = fct_reorder(aisle, n_items)
  ) %>% 
  ggplot(aes(x = aisle, y = n_items, xaxt = "")) + 
  geom_point(alpha = 0.3) + 
  labs(
    title = "Count of Items Ordered per Aisle",
    y = "Number of Items",
    x = "Aisle",
    caption = "Note: Only depicts aisles with >10,000 items ordered."
  ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


**1.4** Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r, message = FALSE}
insta_df %>% 
  mutate(aisle = factor(aisle)) %>% 
  group_by(aisle, product_name) %>% 
  summarize(n_items = n()) %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  mutate(
    item_rank = min_rank(desc(n_items))
    ) %>% 
  filter(item_rank < 4) %>% 
  select(aisle, item_rank, product_name, n_items) %>% 
  arrange(aisle, item_rank) %>% 
  knitr::kable()
```


**1.5** Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r}
insta_df %>% 
  mutate(
    dow = factor(order_dow, labels = c("Sun", "Mon", "Tues", "Weds", "Thurs", "Fri", "Sat"), ordered = TRUE)
  ) %>% 
  group_by(product_name, dow) %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  summarize(mean_time = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = "dow",
    values_from = "mean_time" 
  ) %>% 
  knitr::kable(digits = 2)
```


## Problem 2 - Cleaning and Exploring BRFSS Data

Loading the BRFSS data:

```{r}
data("brfss_smart2010")
```

**2.1 Data cleaning:**

* format the data to use appropriate variable names

* focus on the “Overall Health” topic

* include only responses from “Excellent” to “Poor”

* organize responses as a factor taking levels ordered from “Poor” to “Excellent”

```{r}
brfss_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, county = factor("locationdesc")) %>% 
  filter(topic == "Overall Health", response %in% c("Poor", "Fair", "Good", "Very good", "Excellent")) %>%
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered=TRUE)) %>% 
  arrange(response)
```

**2.2** In 2002, the states that were observed at 7 or more locations were:

```{r}
brfss_df %>% 
  filter(year == 2002) %>% 
  group_by(state) %>% 
  summarize(n_loc = n_distinct(county)) %>% 
  filter(n_loc >= 7) %>% 
  arrange(desc(n_loc)) %>% 
  knitr::kable()
```

In 2010, the states that were observed at 7 or more locations were:

```{r}
brfss_df %>% 
  filter(year == 2010) %>% 
  group_by(state) %>% 
  summarize(n_loc = n_distinct(county)) %>% 
  filter(n_loc >= 7) %>% 
  arrange(desc(n_loc)) %>% 
  knitr::kable()
```


**2.3** Construct a dataset that is limited to `Excellent` responses, and contains year, state, and a variable that averages the `data_value` across locations within a state. 

```{r}
brfss_df_exc_only = brfss_df %>% 
  filter(response == "Excellent") %>% 
  group_by(year, state) %>% 
  summarize(mean_data_value = mean(data_value, na.rm = TRUE))
```

**2.4** Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the `geom_line` geometry and `group` aesthetic will help).

```{r}
brfss_df_exc_only %>% 
  ggplot(aes(x = year, y = mean_data_value)) +
  geom_line(aes(group = state, color = state)) + 
  scale_color_viridis_d() + 
  theme(
    legend.position = "right",
    legend.text = element_text(size = 7)
    ) + 
  labs(
    title = "Proportion of 'Excellent' Responses over Time, by State", 
    y = "Mean Value Across State Locations",
    x = "Year"
  )
```

**2.5** Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

```{r}
brfss_df %>% 
  filter(year %in% c(2006, 2010), state == "NY") %>% 
  ggplot(aes(x = response, y = data_value, fill = response)) +
  geom_boxplot() +
  facet_grid(. ~ year) + 
  labs(
    title = "Disribution of responses across locations in NY state, 2006 vs. 2010", 
    x = "Response", 
    y = "Proportion"
  )
```


## Problem 3 - Accelerometer data from a patient with congestive heart failure

35 days of accelerometer data where activity.* variables are activity counts for each minute of a 24-hour day starting at midnight.

**3.1** Loading, tidying, and wrangling data.

The final dataset includes all originally observed variables and values, has useful variable names, includes a weekday vs. weekend variable, and encodes data with reasonable variable classes.

```{r}
acc_df = read_csv("data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(weekend = ifelse(day %in% c("Saturday", "Sunday"), 1, 0)) %>% 
  mutate(weekend = factor(weekend)) %>% 
  mutate(day = factor(day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"), ordered=TRUE)) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute", 
    names_prefix = "activity_", 
    values_to = "activity_count"
  ) %>% 
  mutate(minute = as.numeric(minute))
```

**3.2** Describing the resulting dataset (e.g. what variables exist, how many observations, etc.):

The original accelerometer dataset included observations from 35 days with 1443 columns, including 1440 activity count variables for each minute in each 24 hour day. After tidying, the accelerometer dataset now contains `r nrow(acc_df)` observations at the minute level that can be further grouped by week, day, or day of the week. This tidy, longer datset now contains only `r ncol(acc_df)` variables: `r colnames(acc_df)`.

**3.3** Traditional analyses of accelerometer data focus on the total activity over the day. Using your tidied dataset, aggregate across minutes to create a total activity variable for each day, and create a table showing these totals. Are any trends apparent?

```{r}

```

**3.4** Accelerometer data allows the inspection activity over the course of the day. Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week. Describe in words any patterns or conclusions you can make based on this graph.

```{r}

```
