p8105\_hw3\_kk3154
================
Kristen King
10/20/2021

``` r
library(tidyverse)
```

    ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --

    ## v ggplot2 3.3.5     v purrr   0.3.4
    ## v tibble  3.1.4     v dplyr   1.0.7
    ## v tidyr   1.1.3     v stringr 1.4.0
    ## v readr   2.0.1     v forcats 0.5.1

    ## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
knitr::opts_chunk$set(
  fid.width = 6, 
  fig.asp = 0.6,
  out.width = "90%")

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis")


scale_color_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1 - Exploring Instacart Data

Loading data from p8105.datasets and the tidyverse:

``` r
library(p8105.datasets)
data("instacart")
```

1.1 Describe the dataset, including size and structure of the data, key
variables, and giving illustrative examples of observations.

``` r
insta_df = instacart
```

The Instacart dataset contains 15 variables of data on 1384617 products
ordered in the instacart app. Each row is one product from each order,
and some identifying variables include order ID, customer ID, day/time
of order, and time since last order. Key variables for potential
analysis include product, aisle, and department IDs and names. For
example, observation \#9 in the dataset indicates customer number 79431
ordered Grated Pecorino Romano Cheese from the specialty cheeses aisle
in the dairy eggs department as part of their order number 36 at time
18:00 on the 6th day of the week.

1.2 How many aisles are there, and which aisles are the most items
ordered from?

1.3 Make a plot that shows the number of items ordered in each aisle,
limiting this to aisles with more than 10000 items ordered. Arrange
aisles sensibly, and organize your plot so others can read it.

1.4 Make a table showing the three most popular items in each of the
aisles “baking ingredients”, “dog food care”, and “packaged vegetables
fruits”. Include the number of times each item is ordered in your table.

1.5 Make a table showing the mean hour of the day at which Pink Lady
Apples and Coffee Ice Cream are ordered on each day of the week; format
this table for human readers (i.e. produce a 2 x 7 table).

## Problem 2 - Cleaning and Exploring BRFSS Data

Loading the BRFSS data:

``` r
data("brfss_smart2010")
```

2.1 Data cleaning:

-   format the data to use appropriate variable names

-   focus on the “Overall Health” topic

-   include only responses from “Excellent” to “Poor”

-   organize responses as a factor taking levels ordered from “Poor” to
    “Excellent”

``` r
brfss_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  filter(topic == "Overall Health", response %in% c("Poor", "Fair", "Good", "Very good", "Excellent")) %>%
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered=TRUE)) %>% 
  arrange(response)
```

2.2 In 2002, which states were observed at 7 or more locations? What
about in 2010?

2.3 Construct a dataset that is limited to `Excellent` responses, and
contains year, state, and a variable that averages the `data_value`
across locations within a state.

``` r
brfss_df_lim = brfss_df %>% 
  filter(response == "Excellent") %>% 
  select(year, state, data_value)
```

2.4 Make a “spaghetti” plot of this average value over time within a
state (that is, make a plot showing a line for each state across years –
the `geom_line` geometry and `group` aesthetic will help).

2.5 Make a two-panel plot showing, for the years 2006, and 2010,
distribution of data\_value for responses (“Poor” to “Excellent”) among
locations in NY State.

## Problem 3 - Accelerometer data from a patient with congestive heart failure

35 days of accelerometer data where activity.\* variables are activity
counts for each minute of a 24-hour day starting at midnight.

3.1 Loading, tidying, and wrangling data.

The final dataset includes all originally observed variables and values,
has useful variable names, includes a weekday vs. weekend variable, and
encodes data with reasonable variable classes.

``` r
acc_df = read_csv("data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(weekend = ifelse(day %in% c("Saturday", "Sunday"), 1, 0)) %>% 
  mutate(weekend = factor(weekend)) %>% 
  mutate(day = factor(day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"), ordered=TRUE)) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute", 
    names_prefix = "activity_", 
    values_to = "activity_count"
  ) %>% 
  mutate(minute = as.numeric(minute))
```

    ## Rows: 35 Columns: 1443

    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...

    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

3.2 Describing the resulting dataset (e.g. what variables exist, how
many observations, etc.):

The original accelerometer dataset included observations from 35 days
with 1443 columns, including 1440 activity count variables for each
minute in each 24 hour day. After tidying, the accelerometer dataset now
contains 50400 observations at the minute level that can be further
grouped by week, day, or day of the week. This tidy, longer datset now
contains only 6 variables: week, day\_id, day, weekend, minute,
activity\_count.

3.3 Traditional analyses of accelerometer data focus on the total
activity over the day. Using your tidied dataset, aggregate across
minutes to create a total activity variable for each day, and create a
table showing these totals. Are any trends apparent?

3.4 Accelerometer data allows the inspection activity over the course of
the day. Make a single-panel plot that shows the 24-hour activity time
courses for each day and use color to indicate day of the week. Describe
in words any patterns or conclusions you can make based on this graph.
